[["index.html", "Case Studies Preface", " Case Studies 2021-04-23 Preface This book is the result of a student projects for Case Studies course at the Warsaw University of Technology. Each team prepared an article on one of the topics selected from reproducibility, imputation, and interpretability. This project is inspired by a book Limitations of Interpretable Machine Learning Methods created at the Department of Statistics, LMU Munich XAI Stories. Case studies for eXplainable Artificial Intelligence done at the Warsaw University of Technology and at the University of Warsaw and ML Case Studies during a case study a year ago. We used the LIML project as the cornerstone for this repository. The cover created by Anna Kozak. Creative Commons License This book is licensed under the Creative Commons Attribution-NonCommercial-ShareAlike 4.0 International License. "],["technical-setup.html", "Technical Setup", " Technical Setup The book chapters are written in the Markdown language. The simulations, data examples and visualizations were created with R (R Core Team 2018) and Python. The book was compiled with the bookdown package. We collaborated using git and github. For details, head over to the book’s repository. References "],["explainable-artificial-intelligence.html", "Chapter 1 Explainable Artificial Intelligence", " Chapter 1 Explainable Artificial Intelligence Author: Anna Kozak Machine Learning is used more and more in virtually any aspect of our life. We train models to predict the future in banking, telecommunication, insurance, industry, and many other areas. The models give us predictions, however, very often we do not know how they are calculated. Can we trust these predictions? Why should we use the results of models which we do not fully understand? This results in a lack of understanding of the results obtained, so there is now a strong need to explain the decisions made by the non-interpretable models called black boxes. There are several tools for exploring and explaining the predictive models, which allow to understanding how they are works. During the class, we explored methods of explaining global as well as local, which you can read more about in the Explanatory Model Analysis (Biecek and Burzykowski 2021) book. Teams work on data from a Kaggle that described problems in the world around us. Each team was responsible for analyzing, modeling, and building explanations for complex models. Each chapter includes a story about how to use explainable AI to understand the model. References "],["xai1-explainable-cards.html", "1.1 Explaining Credit Card Customers churns", " 1.1 Explaining Credit Card Customers churns Authors: Katarzyna Solawa, Przemysław Chojecki, Bartosz Sawicki (Warsaw University of Techcnology) "],["ml-in-predition-of-real-estate-prices.html", "1.2 ML in predition of real estate prices", " 1.2 ML in predition of real estate prices Authors: Sebastian Deręgowski, Maciej Gryszkiewicz, Paweł Morgen (Warsaw University of Technology) 1.2.1 Abstract Lorem ipsum 1.2.2 Introduction Lorem ipsum 1.2.3 Related Work Lorem ipsum 1.2.4 Methodology Lorem ipsum 1.2.5 Results Lorem ipsum 1.2.6 Summary and conclusions Lorem ipsum "],["xai-heart-disease.html", "1.3 How not to have broken heart &lt;3", " 1.3 How not to have broken heart &lt;3 Authors: Przybyłek Paulina, Rólkiewicz Renata, Słowakiewicz Patryk 1.3.1 Introduction "],["xai1-explainable-wine.html", "1.4 Wines", " 1.4 Wines Authors: Jakub Kosterna, Bartosz Siński, Jan Smoleń "],["xai1-explainable-hotels.html", "1.5 eXplaining predictions of booking cancelations", " 1.5 eXplaining predictions of booking cancelations Authors: Mateusz Krzyziński, Anna Urbala, Artur Żółkowski (Warsaw University of Technology) 1.5.1 Introduction Introduction "],["explainable-artificial-inteligence-r.html", "Chapter 2 Explainable artificial inteligence (R)", " Chapter 2 Explainable artificial inteligence (R) "],["deep-learning-1.html", "Chapter 3 Deep Learning 1", " Chapter 3 Deep Learning 1 "],["deep-learning-2.html", "Chapter 4 Deep Learning 2", " Chapter 4 Deep Learning 2 "],["machine-learning.html", "Chapter 5 Machine Learning", " Chapter 5 Machine Learning Author: Hubert Baniecki An ever-growing domain of machine learning decision systems in medicine has crossed ways with the COVID-19 pandemic. Precariously, a vast majority of the proposed predictive models focus on achieving high performance; while overlooking comprehensive validation. Nowadays, providing representative data, model explainability, even bias detection become mandatory for responsible prediction making in high-stakes medical applications. The following chapters introduce new views into the already published work on the topic of patients’ COVID-19 mortality prognosis using supervised machine learning: 1. TBA 2. TBA 3. TBA 4. TBA "],["one-model-to-fit-them-all-covid-19-mortality-prediction-using-multinational-data.html", "5.1 One model to fit them all: COVID-19 mortality prediction using multinational data", " 5.1 One model to fit them all: COVID-19 mortality prediction using multinational data Authors: Kurek Marcelina, Stączek Mateusz, Wiśniewski Jakub, Zdulska Hanna 5.1.1 Introduction "],["transparent-machine-learning-to-support-predicting-covid-19-infection-risk-based-on-chronic-diseases.html", "5.2 Transparent Machine Learning to Support Predicting COVID-19 Infection Risk Based on Chronic Diseases", " 5.2 Transparent Machine Learning to Support Predicting COVID-19 Infection Risk Based on Chronic Diseases Authors: Hubert Ruczyński, Dawid Przybyliński, Kinga Ulasik 5.2.1 Introduction "],["rashomonml.html", "Chapter 6 RashomonML", " Chapter 6 RashomonML "],["roshomon-sets-on-death-prediction-xgb-models-using-mimic-iii-database.html", "6.1 Roshomon sets on death prediction XGB models using MIMIC-III database", " 6.1 Roshomon sets on death prediction XGB models using MIMIC-III database Authors: Ada Gąssowska, Elżbieta Jowik (Warsaw University of Techcnology) "]]
