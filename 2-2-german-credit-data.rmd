## Classifying people as good or bad credit risks {#xai1-explainable-german-credits}

*Authors: Paweł Fijałkowski, Paulina Jaszczuk, Jakub Szypuła (Warsaw University of Technology)*

### Introduction

### Dataset and models

During entire analysis, we'll be operating on publicly available data set containing information about German borrowers. Input was processed/collected by Professor Dr. Hans Hofmann from [University of Hamburg](https://www.uni-hamburg.de/en.html) and is available [here](https://archive.ics.uci.edu/ml/datasets/statlog+(german+credit+data)).

Data set provider, basing on academic research,  have chosen certain variables to describe each borrower. That combination of numerical and qualitative variables proved to carry certain importance/influence on probability of paying back borrowed assets. 

Brief overview of statistics describing an observation (columns in data set):

Statistic                 Explanation
-----------------------   ----------------------------- 
checking_status           Status of existing checking account (qualitative)
duration                  Credit duration in months (numerical)
credit_history            Credit history (qualitative)
purpose                   Purpose (qualitative)
credit_amount             Credit amount (numerical)
savings_status            Savings account/bonds (qualitative)
employment                Present employment since (qualitative)
installment_commitment    Installment rate in percentage of disposable income (numerical)
personal_status           Personal status and sex (qualitative)
other_parties             Other debtors / guarantors (qualitative)
residence_since           Present residence since (numerical)
property_magnitude        Property ownership (qualitative)
age                       Age in years (numerical)
other_payment_plans       Other installment plans (qualitative)
housing                   Current housing deal (qualitative)
existing_credits          Number of existing credits (numerical)
job                       Job type quality (qualitative)
num_dependents            Number of people being liable to provide maintenance for (numerical)
own_telephone             Ownership of telephone (qualitative)
foreign_worker            Worker from abroad (qualitative)


Author also suggest using cost function that "punishes" model more for false-positives (classification of bad customer as a good one) than for false-negatives. For a model user (i.e bank-owner), it is much worse to classify bad customer as a good one, than the other way around.

After careful deliberation and testing using multiple metrics the team decided to use random forest as a baseline model for further modeling and explanations. Random forest is a supervised machine learning algorithm, basing on a simple idea of decision tree. Each decision tree is making a classification prediction and then their votes are counted/merged. Only difference between
standard forest voting and random forest is that in the latter case, only random subset of features is considered during selecting most important feature (with lowest gini index value).
Model performed exceptionally good during cross-validation, even without fine parameter hyper-tuning.

### Local explanations

To better understand the behavior of Random Forest, we employed a set of machine learning explanation methods. In order to comprehend the reasoning behind model predictions and interactions between variables we began at the local level, i.e. single observation. This way, we could compare influence of each variable within a clearly defined context of every potential borrower. Our primary motivation in selecting observations to present in this paper was to show how variables interact with one another in our model in creating predictions. As a result, selection varies depending on the method.

Methods employed by us were Break-down, SHAP, LIME and Ceteris Paribus.

#### Break-down method

We began by analyzing the output of the Break-down method. Once compared side-by-side (see the figure) several key differences emerge. First of all, the importance of checking status variable (which will return in forthcoming sections). One can also notice the importance of the "age" variable, which seems intuitive. A further conclusion can be drawn from this - influence of a variable depends on its value. In fact, depending on interactions between variables in the data set even the same value can have opposite effects. An example (although miniscule) can be found by comparing observations 60 and 230. The same value of "purpose" variable (i.e. "furniture/equipment") gives opposite influences (-1.6% "good" probability and +0.4% respectively). Thus we should always take into account context in which each variable is evaluated.
 
Regarding specific conjectures on the data set one can draw from this comparison, we can see that both observations share 7 out of the top 10 most influential variables. Among them are, for example age, checking status, which would be expected by a "common sense" intuition. Influences confirm that intuition. Young age contributes negatively towards credit rating and lower duration positively. Same for checking status - the higher the better. 

```{r 2-2-breakdown, out.width="700", fig.align="center", echo=FALSE, fig.cap='Comparison of plots of breakdown method for two observations - number 1 (left) and number 94 (right). Positive values indicate an increase in probability of being classified as a "good" borrower while negative values indicate the opposite.'}
knitr::include_graphics('C:\\Users\\pauli\\OneDrive\\Pulpit\\2-2-breakdown-comparison.png')
```

#### Shap method

Consequently, we used SHAP method to analyze the first observations and compare results with the Break-Down method. The results of this can be seen in the figure below. Duration and checking status remain the two most important variables, while age grows in importance. 8 of the top 10 variables remain the same, with around the same influences. The major difference being absence of information on existing credits and residence since, have been replaced with credit amount and purpose. This method offers new information, primarily about the variation of influence of each variable. One can notice that age is the most varied (since it can affect the prediction both positively and negatively), which again would correspond to the "common sense" intuition (as with duration, the credit amount and checking status). The opposite occurs with credit history, purpose, property magnitude and length of employment, where variation remains lower compared to influence. Changes, in order of importance are rather small, only the installment commitment moves by more than 3 places (from number 5 to number 10). The rest is swapping of checking status and duration, fall of property magnitude by 2 places, employment by 1 place and rise of age by 2 places. It should be noted that all these changes occur similar or very similar absolute influence values in break-down method. One can judge that importance of variables is a trait that can remain consistent between various explanation methods.

```{r 2-2-breakdown2, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of results of SHAP method for 1st observation'}
knitr::include_graphics('2-2-shap.png')
```

#### False positive and false negative predictions

Although the accuracy of our model is at satisfactory level, sometimes it is providing incorrect predictions. We decided to take a closer look and analyze the situations when our model misclassifies. For this purpose we explained the false positives and false negatives predictions with the local methods LIME and SHAP.

##### False positive

```{r 2-2-lime_false_pos, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of results of LIME method for 56th observation which was missclasified by our model and predicted as false positive'}
knitr::include_graphics('2-2-lime_false_pos.png')
```

The model classified the observation positively mainly on the basis of the features duration (12 months) and savings status (no known savings). This is in line with our earlier conclusions - a short loan duration has a positive effect on prediction. 

To better understand the operation of the model in this case, we also made an explanation using the SHAP method. 

```{r 2-2-shap_false_pos, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of results of SHAP method for 56th observation which was missclasified by our model and predicted as false positive'}
knitr::include_graphics('2-2-shap_false_pos.png')
```

The explanations agree on the influence of feature savings status but according to the SHAP method, duration has a marginal positive effect on prediction. Interestingly, both methods give checking status as the most influential feature. Its value (in the range from 0 to 200) negatively affects the prediction which is how the model should classify this observation but this is outweighed by the positive effects of other features.

##### False negative

```{r 2-2-lime_false_neg, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of results of LIME method for 945th observation which was missclasified by our model and predicted as false negative.'}
knitr::include_graphics('2-2-lime_false_neg.png')
```

The model's prediction was not certain, but it indicated that the client is a bad borrower with a probability of 65%. The biggest negative contributions are related to checking status (in the range from 0 to 200), credit history (no credits/all paid) and duration (48 months). While the relatively long loan term may indeed have a negative effect on the prediction, the fact that there are no other loans seems to be contradictory. The LIME method did not answer all our questions. To dispel any doubts we also explained the observations using the SHAP method.

```{r 2-2-shap_false_neg, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of results of SHAP method for 945th observation which was missclasified by our model and predicted as false negative.'}
knitr::include_graphics('2-2-shap_false_neg.png')
```

SHAP's explanations are very similar to those LIME's ones. 
Again, features duration, checking status and credit hisotry have the greatest influence on negative prediction. Perhaps the strange contribution of the feature credit history is due to its interaction with other variables.


### Global explanations

A major shortcoming of local explanations is that they are just that - local. It is the ability to see "the bigger picture" that allows us to achieve a better understanding of the model. Thus, we resolved to using Global Explanation methods in order to properly grasp approach behind predictions in our machine learning model.

#### Feature Importance

First of all, we began with Feature Importance method which gives information on the importance of features in the model. The results of applying this method on our model can be seen in the figure below. As one can notice, results are in line with local explanations. That is, the domination of such features as checking status, credit duration and credit amount. Then follows age, saving status and purpose. Yet again, our "common sense" intuition seems 	to be confirmed. Noteworthy, the plot resembles an exponential function, hinting that predictions are based mostly on the first few most important features, a trait not so obvious to observe in local explanations. If we assume that the model is correct, then we can also draw conclusions regarding the "real life" importance of features. Those results should still be compared with other Global Explanation methods. 

```{r 2-2-feature_importance, out.width="700", fig.align="center", echo=FALSE, fig.cap='A plot of Feature Importance values for each variable for our model.'}
knitr::include_graphics('2-2-feature_importance.png')
```

### Summary and conclusions