## BCDUNet

*Authors: Maria Kałuska, Paweł Koźmiński, Mikołaj Spytek (Warsaw University of Technology)*

### Abstract

Some text will be here in the future

### Introduction

Being able to reproduce results presented in published papers is a significant part of the scientific process. It is important mainly because it allows other scientists to verify that the method produces consistant results. The main goal of our work was to reproduce the results of the BCDU-Net deep neural network [@3-2-bcdu] and to check if the source code provided with the paper was of sufficient quality so as to add our own modifications to the network. We focused on working with the verison of the network which performed a lung segmentation task.

The architecture of the BCDU network is based on U-Net [@3-2-unet] which takes its name from the shape of the model. Both, the original and the improved models consist of max-pooling layers, convolutional layers and up-convolutional layers, but what makes BCDU-net stand out, is the usage of BConvLSTM cells. They allow easier flow of information between the first and last layers of the model, which in turn improves the performance.

#### Dataset

The dataset used by the authors of the article was downloaded from Kaggle ![link do danych]() and consists of eight files 
in NIfTI(Neuroimaging Informatics Technology Initiative) format. There are four 3D CT scans of human chest, 
the other four files are corresponding masks. Each photo consists of horizontal sections with the resolution 512x512.
 After unpacking those images, there were about 1200 horizontal images of lungs and corresponding masks. ![Lungs with mask](images/3-2-dataset.png)

##### Preprocessing

The preprocessing applied to the lung images was to normalize the grayscale to the range $[0, 255]$ and to remove blood vessels and bones. 
In addition, horizontal sections consisting only of black pixels have been removed. In the case of masks, all pixels have been limited 
to the value set $\{0, 1\}$. Moreover, masks around the lung area were generated, and binary erosion was also used in the photos prepared in this way.

#### Execution

The code repository provided with the article contained all the necessary files to train the model and obtain results. At first we didn't see if the authors attached information about the versions of packages they used, so we decided to try the following: `keras==2.4.3`, `tensorflow==2.4.1`, `scikit-learn==0.24.1`, `numpy==1.19.5`, `matplotlib==3.3.4` and ran the code in `python 3.8.7`. Much later it turned out that the list of versions of packages was included in one of the pull requests in the Github repository, but we decided to stick with the ones chosen by us, as by then they worked and allowed us to obtain results.

Even though the code was mostly functional, it still required some debugging. Some errors seemed as though they were simple omissions, whereas some might have been the result of us using slightly different versions of packages. In order to get the model to work we: added `import os` to the `Prepare_data.py` file, added `import numpy as np` to the `models.py` file, changed argument names from `input, output` to `inputs, outputs` in the definition of the model in the `models.py` file. After implementing these changes we succesfully trained and evaluated the model.

Even though at this moment the model was working, it was extremely slow. It was due to the fact that the calculations were being carried out using the CPU. To improve training speed we installed the cuDNN library, so that we were able to use the performance of our graphics cards.


### Experiments

#### Regularization

As one of the modifications to the BCDU network we tried adding regularization to the models' layers. Including this penalizes the neural network for learning weights of high magnitude. Doing so makes the network a bit less complex, but can often lead to an improvment of the results. The two main methods of applying regularization are l1 and l2. In l1 regularization the penalty is proportional to the absolute value of the parameter, whereas in l2 regularization it is proportional to the sqare of of the weight. As such, l2 regularization is stronger when the values of parameters are higher, and weaker when they are lower.

We tried applying both l1, and l2 regularization to the original model. The results of our testing have shown, that l2 regularization with the parameter $\lambda=10^{-3}$ scored the best. However the results are still somewhat lower than the results of the original network. The masks generated by the model with l2 regularization applied are shown on the figure below.

![Results of l2-regularized model](images/3-2-l2-regularization.png)

#### Additional preprocessing

Even though the authors of the model already implemented some preprocessing features such as removing artefacts, we've decided to try some methods used to change the input pictures. They are often used as a way to improve the performance of a model. We tried two methods of altering the pictures: histogram stretching and histogram equalization.

Contrast stretching is a technique, which allows the image to take up the entire brightness spectrum. The metod works by scaling the interval of the brightness values which appear in the image, to the whole available space. In traditional imaging that would be the interval $[0,255]$, but in our network $[0,1]$ as BCDU-net uses values from the unit interval. In the case of our images, they were already scaled such that the lowest and highest values already appear in each picture. Because of that our implementation of histogram stretching didn't have any effect on the pictures.

The other method we've tried produced far greater results. Histogram equalization works by changing pixels' brightness values such that the number of pixels of each brightness is approximately equal. There is however one modification we applied to this method. The value of zero contains valuable information in the case of our task. Because of that we left pixels of this value unchanged and applied the equalization only to positive values of brightness. The resulting images can be seen below.

![Histogram equalization](images/3-2-hist_eq.png)

We've trained the original architecture from the BCDU-net article using data preprocessed with histogram equalization. The results were lower than these achieved by the original model. 


#### GAN for CT images

##### CycleGAN

First idea was to use available CycleGAN[@3-2-cycle-gan] to transfer non-contrast images to contrast images, this approach changes just the grayscale on image and does not change the shape of lungs, so we wouldn't have to generate additional masks.
However to use CycleGAN one need to have both datasets: contrast and noncontrast.
We had only one data set. Therefore images after histogram equalization were used as contrast images. 
To generated images and corresponding masks dilation with random kernel was applied, it was in order to diversify the initial dataset from the generated dataset. 
This action resulted in reduction of the lung area. 
![CyceGAN results](images/3-2-cycle_gan.png)

Secondly, a mix of both inital and generated dataset was used to train the BCDU-net. Unfortunately, the training results were significantly worse. It might have happened due to the small differences between generated images' ground truth 
masks and masks generated by us.

##### DCGAN

The next approach was to generate images and masks from noise with DCGAN by supplying on Discriminator's input both image and corresponding to it mask. 
This approach has been previously applied to chest X-ray images generation [@3-2-gan-cxr].
The aim was to teach generator to generate image with corresponding mask simultaneously. The issue with this approach was that such a network requires hours of learning on strong GPU. 
Therefore only the code was implemented and run on not enough number  of
epochs, which did not give satisfying results.

#### Dual output model

The goal was to help the person who interprets the photos locate them in the human body. 
Therefore, apart from the masks, we decided to generate labels informing about where a given lung section is located. 
There were two possible locations 'upper' and 'lower'. 
The division was based on the image below. The uppert part is the part above human heart. ![Lung's division](images/3-2-lung_division.png)

The newly created network consisted of two branches. The first branch was the BCDUNet network, while the second branch responsible for the classification of photos was the ResNet[@3-2-resnet] network. 
It has been slightly modified so that it could be used in a two-output model.

Despite the small number of epochs = 2, the model results are satisfactory.

**Classification results**

| Accuracy        | Sensitivity           | Precision  | F1 Score |
| ------------- |-------------| -----|-------------|
| 0.9221     | 0.6066 | 1 | 0.7551 |

Below you can see lung images, masks and their labels.
![Images with labels](images/3-2-images_dual_output.png)

### Conclusion

**Results**

| | Accuracy | Jaccard score | F1 score | ROC AUC |
|---|---|---|---|---|
original model | 0.9961 | 0.9741 | 0.9869 | 0.9933 |
arbitrary modifications | 0.8955 | 0.2904 | 0.4501 | 0.6453 |
auxiliary task | 0.9933 | 0.9660 | 0.9827 | 0.9926 |
histogram equalization | 0.9860 | 0.9313 | 0.9644 | 0.9883 |
l2 regularization | 0.9867 | 0.9311 | 0.9643 | 0.9693 |

TODO
