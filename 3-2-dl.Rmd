## BCDUNet

*Authors: Maria Kałuska, Paweł Koźmiński, Mikołaj Spytek*

### Abstract

Some text will be here in the future

### Introduction

TODO
### Dataset

The dataset used by the authors of the article was downloaded from Kaggle ![link do danych]() and consists of eight files 
in NIfTI(Neuroimaging Informatics Technology Initiative) format. There are four 3D CT scans of human chest, 
the other four files are corresponding masks. Each photo consists of horizontal sections with the resolution 512x512.
 After unpacking those images, there were about 1200 horizontal images of lungs and corresponding masks. ![Lungs with mask](images/3-2-dataset.png)

#### Preprocessing

The preprocessing applied to the lung images was to normalize the grayscale to the range [0, 255] and to remove blood vessels and bones. 
In addition, horizontal sections consisting only of black pixels have been removed. In the case of masks, all pixels have been limited 
to the value set {0, 1}. Moreover, masks around the lung area were generated, and binary erosion was also used in the photos prepared in this way.

### Experiments

#### GAN for CT images

##### CycleGAN

First idea was to use available CycleGAN[@3-2-cycle-gan] to transfer non-contrast images to contrast images, this approach changes just the grayscale on image and does not change the shape of lungs, so we wouldn't have to generate additional masks.
However to use CycleGAN one need to have both datasets: contrast and noncontrast.
We had only one data set. Therefore images after histogram equalization were used as contrast images. 
To generated images and corresponding masks dilation with random kernel was applied, it was in order to diversify the initial dataset from the generated dataset. 
This action resulted in reduction of the lung area. 
![CyceGAN results](images/3-2-cycle_gan.png)

Secondly, a mix of both inital and generated dataset was used to train the BCDU-net. Unfortunately, the training results were significantly worse. It might have happened due to the small differences between generated images' ground truth 
masks and masks generated by us.

##### DCGAN

The next approach was to generate images and masks from noise with DCGAN by supplying on Discriminator's input both image and corresponding to it mask. 
This approach has been previously applied to chest X-ray images generation [@3-2-gan-cxr].
The aim was to teach generator to generate image with corresponding mask simultaneously. The issue with this approach was that such a network requires hours of learning on strong GPU. 
Therefore only the code was implemented and run on not enough number  of
epochs, which did not give satisfying results.

#### Dual output model

The goal was to help the person who interprets the photos locate them in the human body. 
Therefore, apart from the masks, we decided to generate labels informing about where a given lung section is located. 
There were two possible locations 'upper' and 'lower'. 
The division was based on the image below. The uppert part is the part above human heart. ![Lung's division](images/3-2-lung_division.png)

The newly created network consisted of two branches. The first branch was the BCDUNet network, while the second branch responsible for the classification of photos was the ResNet[@3-2-resnet] network. 
It has been slightly modified so that it could be used in a two-output model.

Despite the small number of epochs = 2, the model results are satisfactory.

**Classification results**

| Accuracy        | Sensitivity           | Precision  | F1 Score |
| ------------- |-------------| -----|-------------|
| 0.9221     | 0.6066 | 1 | 0.7551 |

Below you can see lung images, masks and their labels.
![Images with labels](images/3-2-images_dual_output.png)

### Conclusion

TODO
