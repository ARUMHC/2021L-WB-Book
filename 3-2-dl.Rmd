## BCDUNet

*Authors: Maria Kałuska, Paweł Koźmiński, Mikołaj Spytek (Warsaw University of Technology)*

### Abstract

Some text will be here in the future

### Introduction

Being able to reproduce results presented in published papers is a significant part of the scientific process. It is important mainly because it allows other scientists to verify that the method produces consistant results. The main goal of our work was to reproduce the results of the BCDU-Net deep neural network [@3-2-bcdu] and to check if the source code provided with the paper was of sufficient quality so as to add our own modifications to the network. We focused on working with the verison of the network which performed a lung segmentation task.

The architecture of the BCDU network is based on U-Net [@3-2-unet] which takes its name from the shape of the model. Both, the original and the improved models consist of max-pooling layers, convolutional layers and up-convolutional layers, but what makes BCDU-net stand out, is the usage of BConvLSTM cells. They allow easier flow of information between the first and last layers of the model, which in turn improves the performance.

#### Dataset

The dataset used by the authors of the article was downloaded from Kaggle ![link do danych]() and consists of eight files 
in NIfTI(Neuroimaging Informatics Technology Initiative) format. There are four 3D CT scans of human chest, 
the other four files are corresponding masks. Each photo consists of horizontal sections with the resolution 512x512.
 After unpacking those images, there were about 1200 horizontal images of lungs and corresponding masks. ![Lungs with mask](images/3-2-dataset.png)

##### Preprocessing

The preprocessing applied to the lung images was to normalize the grayscale to the range [0, 255] and to remove blood vessels and bones. 
In addition, horizontal sections consisting only of black pixels have been removed. In the case of masks, all pixels have been limited 
to the value set {0, 1}. Moreover, masks around the lung area were generated, and binary erosion was also used in the photos prepared in this way.

#### Execution

The code repository provided with the article contained all the necessary files to train the model and obtain results. At first we didn't see if the authors attached information about the versions of packages they used, so we decided to try the following: `keras==2.4.3`, `tensorflow==2.4.1`, `scikit-learn==0.24.1`, `numpy==1.19.5`, `matplotlib==3.3.4` and ran the code in `python 3.8.7`. Much later it turned out that the list of versions of packages was included in one of the pull requests in the Github repository, but we decided to stick with the ones chosen by us, as by then they worked and allowed us to obtain results.

Even though the code was mostly functional, it still required some debugging. Some errors seemed as though they were simple omissions, whereas some might have been the result of us using slightly different versions of packages. In order to get the model to work we: added `import os` to the `Prepare_data.py` file, added `import numpy as np` to the `models.py` file, changed argument names from `input, output` to `inputs, outputs` in the definition of the model in the `models.py` file. After implementing these changes we succesfully trained and evaluated the model.

Even though at this moment the model was working, it was extremely slow. It was due to the fact that the calculations were being carried out using the CPU. To improve training speed we installed the cuDNN library, so that we were able to use the performance of our graphics cards.


### Experiments

#### GAN for CT images

##### CycleGAN

First idea was to use available CycleGAN[@3-2-cycle-gan] to transfer non-contrast images to contrast images, this approach changes just the grayscale on image and does not change the shape of lungs, so we wouldn't have to generate additional masks.
However to use CycleGAN one need to have both datasets: contrast and noncontrast.
We had only one data set. Therefore images after histogram equalization were used as contrast images. 
To generated images and corresponding masks dilation with random kernel was applied, it was in order to diversify the initial dataset from the generated dataset. 
This action resulted in reduction of the lung area. 
![CyceGAN results](images/3-2-cycle_gan.png)

Secondly, a mix of both inital and generated dataset was used to train the BCDU-net. Unfortunately, the training results were significantly worse. It might have happened due to the small differences between generated images' ground truth 
masks and masks generated by us.

##### DCGAN

The next approach was to generate images and masks from noise with DCGAN by supplying on Discriminator's input both image and corresponding to it mask. 
This approach has been previously applied to chest X-ray images generation [@3-2-gan-cxr].
The aim was to teach generator to generate image with corresponding mask simultaneously. The issue with this approach was that such a network requires hours of learning on strong GPU. 
Therefore only the code was implemented and run on not enough number  of
epochs, which did not give satisfying results.

#### Dual output model

The goal was to help the person who interprets the photos locate them in the human body. 
Therefore, apart from the masks, we decided to generate labels informing about where a given lung section is located. 
There were two possible locations 'upper' and 'lower'. 
The division was based on the image below. The uppert part is the part above human heart. ![Lung's division](images/3-2-lung_division.png)

The newly created network consisted of two branches. The first branch was the BCDUNet network, while the second branch responsible for the classification of photos was the ResNet[@3-2-resnet] network. 
It has been slightly modified so that it could be used in a two-output model.

Despite the small number of epochs = 2, the model results are satisfactory.

**Classification results**

| Accuracy        | Sensitivity           | Precision  | F1 Score |
| ------------- |-------------| -----|-------------|
| 0.9221     | 0.6066 | 1 | 0.7551 |

Below you can see lung images, masks and their labels.
![Images with labels](images/3-2-images_dual_output.png)

### Conclusion

TODO
